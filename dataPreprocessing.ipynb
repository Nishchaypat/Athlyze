{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic Segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import PyPDF2\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "def initialize_model():\n",
    "    model = GoogleGenerativeAI(\n",
    "        model=\"gemini-1.0-pro\",\n",
    "        google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def clean_response(response_str):\n",
    "    \"\"\"\n",
    "    Cleans the response string by removing the code block markers and then attempts to convert it to JSON.\n",
    "    \"\"\"\n",
    "    # Remove the code block markers (start and end)\n",
    "    response_str = re.sub(r'^```json\\n', '', response_str)\n",
    "    response_str = re.sub(r'```$', '', response_str).strip()\n",
    "    \n",
    "    # Attempt to parse the cleaned string into a JSON object\n",
    "    try:\n",
    "        response_json = json.loads(response_str)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing the response as JSON, response was:\", response_str)\n",
    "        return {\"findings\": [], \"metadata\": {}}\n",
    "\n",
    "def chunk_and_clean_text(model, raw_text):\n",
    "    prompt = \"\"\"\n",
    "    You are a highly capable AI model tasked with cleaning and chunking the provided text.\n",
    "    Please return the response in JSON format with two keys:\n",
    "    - \"findings\": A list of valid claims or facts related to muscle training, nutrition, gym, biology, etc.\n",
    "    - \"metadata\": A dictionary containing the \"title\" key with the paper's title.\n",
    "    Here is the input text: {raw_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # Get response from Gemini model (in string format)\n",
    "    response_str = model(prompt.format(raw_text=raw_text))\n",
    "        \n",
    "    # Clean and parse the response string into a JSON object\n",
    "    response_json = clean_response(response_str)\n",
    "    \n",
    "    findings = response_json.get(\"findings\", [])\n",
    "    metadata = response_json.get(\"metadata\", {})\n",
    "    \n",
    "    return {\"findings\": findings, \"metadata\": metadata}\n",
    "\n",
    "def process_pages(pages):\n",
    "    model = initialize_model()\n",
    "    full_response = {\"findings\": [], \"metadata\": {}}\n",
    "    \n",
    "    for page in pages:\n",
    "        print(f\"Processing page {pages.index(page) + 1}...\")\n",
    "        response = chunk_and_clean_text(model, page)\n",
    "        \n",
    "        # Print the response for debugging purposes\n",
    "        print(\"Response:\", response)  # Print the response to verify it's in the correct format\n",
    "        \n",
    "        # Merge findings from the response\n",
    "        if isinstance(response, dict):\n",
    "            # Append findings to full_response['findings']\n",
    "            full_response[\"findings\"].extend(response.get(\"findings\", []))\n",
    "            \n",
    "            # Merge metadata if it's not already set\n",
    "            if not full_response[\"metadata\"]:\n",
    "                full_response[\"metadata\"] = response.get(\"metadata\", {})\n",
    "        else:\n",
    "            print(\"Response is not in the expected format:\", response)\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "# Extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        pages = []\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            pages.append(page_text)\n",
    "    return pages\n",
    "\n",
    "\n",
    "# Path to your PDF file\n",
    "file_path = \"nutrition_research_papers/nutrients-11-01136.pdf\"\n",
    "# Extract text from the PDF using PyPDF2\n",
    "print(\"Extracting text from PDF using PyPDF2...\")\n",
    "pages = extract_text_from_pdf(file_path)\n",
    "print(len(pages))\n",
    "# Perform chunking and cleaning\n",
    "print(\"Cleaning and chunking text from each page...\")\n",
    "final_response = process_pages(pages)\n",
    "\n",
    "# Output the final response\n",
    "print(final_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athlyze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
